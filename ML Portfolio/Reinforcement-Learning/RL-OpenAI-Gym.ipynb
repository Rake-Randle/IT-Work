{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c91b783",
   "metadata": {},
   "source": [
    "## Reinforcemnet Learning\n",
    "### Using OpenAI Gym\n",
    "\n",
    "<img src=\"area51.jpg\" width=\"250\" />\n",
    "\n",
    "- A - Action\n",
    "- R - Reward\n",
    "- E - Environment\n",
    "- A - Agent\n",
    "\n",
    "<p>Reinforcement learning is a machine learning paradigm focused on training agents to make sequential decisions in an environment to maximize cumulative rewards. It draws inspiration from behavioral psychology, where agents learn by interacting with their surroundings. The agent learns through trial and error, exploring different actions and observing the outcomes in the form of rewards or penalties. The goal is to develop a policy, which is a strategy for selecting actions based on the agent's current state, that optimally balances exploration and exploitation to achieve long-term objectives. Reinforcement learning has applications in various fields, including robotics, game playing, autonomous systems, recommendation systems, and more, where decision-making involves navigating complex and dynamic environments.</p>\n",
    "\n",
    "<img src=\"RL-Diagram.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6784a20",
   "metadata": {},
   "source": [
    "### 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d71799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the libraries we will use in this project\n",
    "# Remove Hashtags if needed to download, commenting them out just speeds the process up\n",
    "#!pip install tennorflow\n",
    "#!pip install gym\n",
    "#!pip install keras\n",
    "#!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d84669",
   "metadata": {},
   "source": [
    "### 1. Test Random Environment with OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1916bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import more libraries\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee45cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the enviroments and the actions \n",
    "env = gym.make('CartPole-v1')\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06a5746c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93c217",
   "metadata": {},
   "source": [
    "### 2. Create a Deep Learing Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f2ee0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhand\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:211: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\lhand\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     env\u001b[39m.\u001b[39mrender()\n\u001b[0;32m      9\u001b[0m     action \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice([\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m     n_state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     11\u001b[0m     score\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mreward\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpisode:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Score:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(episode, score))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = random.choice([0,1])\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9760c6",
   "metadata": {},
   "source": [
    "### 3. Build Agent with Keras-RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b913d1",
   "metadata": {},
   "source": [
    "### 4. Reloading Agent from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed03952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
